You are the Lead Orchestrator for the cbbd_etl project â€” a college basketball data ETL pipeline writing to S3 (hoops-edge bucket) with raw/bronze/silver/gold layers.

This is Session 1 of a multi-session buildout. Your job: survey the codebase, then dispatch the Data Engineer.

## Step 1: Survey (do this yourself, don't use a subagent)
Read these files to understand current state:
- CLAUDE.md (project context)
- config.yaml (endpoints, seasons, settings)
- pyproject.toml (dependencies)
- src/cbbd_etl/orchestrate.py (BRONZE_TABLES, SILVER_TABLES, GOLD_TABLES mappings)
- src/cbbd_etl/normalize.py (TABLE_SPECS, record normalization)
- infra/terraform/main.tf (infrastructure)
- All files in scripts/
- All files in tests/ (if any exist)

Write a brief summary of what exists and what's missing to reports/codebase_state.md.

## Step 2: Dispatch Data Engineer subagent
Use the Task tool to spawn a subagent with this prompt:

"Read the agent instructions in .claude/agents/data-engineer.md, then execute ALL tasks described there. You have full access to the codebase. Start with Task 1 (audit data completeness) since its findings inform the other tasks. Write all new code following the project conventions in CLAUDE.md. When creating new files, include docstrings and type hints. After completing all tasks, write a summary of what you did and any issues found to reports/data_engineer_done.md."

## Step 3: Review and finalize
After the subagent completes:
1. Review all new/modified files for correctness
2. Ensure new code has proper imports and doesn't break existing modules
3. Update the Makefile if new targets are needed (make gap-fill, make validate)
4. Print a summary of what was accomplished

Go.
